{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Gv20O0OW44N9",
   "metadata": {
    "id": "Gv20O0OW44N9"
   },
   "source": [
    "<head>\n",
    "  <meta name=\"author\" content=\"Rogério de Oliveira\">\n",
    "  <meta institution=\"author\" content=\"Universidade Presbiteriana Mackenzie\">\n",
    "</head>\n",
    "\n",
    "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\" width=300, align=\"right\">\n",
    "\n",
    "<h1 align=left><font size = 8><b>Inteligência Artificial</b></font></h1>\n",
    "<h1 align=left><font size = 6><b>Deep Learning</b></font></h1>\n",
    "\n",
    "# Atividade: T4 - Atividade de aprofundamento\n",
    "\n",
    "Nome: Bruno Rebocho de Toledo\n",
    "\n",
    "Turma: 01B\n",
    "\n",
    "Matrícula: 92316328"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c698c72-7277-4299-b593-24904b79f511",
   "metadata": {
    "id": "7c698c72-7277-4299-b593-24904b79f511"
   },
   "source": [
    "---\n",
    "## Introdução\n",
    "\n",
    "Este notebook tem como objetivo explorar as capacidades de classificação de redes neurais com TensorFlow e Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2833d-67fa-4313-a5ab-a15808fa4659",
   "metadata": {
    "id": "0da2833d-67fa-4313-a5ab-a15808fa4659"
   },
   "source": [
    "---\n",
    "## Dataset \"Predict students' dropout and academic success\"[1]\n",
    "\n",
    "O conjunto de dados escolhido, criado a partir de uma instituição de ensino superior (adquirido de várias bases de dados independentes), descreve estudantes matriculados em diferentes graduações, como agronomia, design, educação, enfermagem, jornalismo, gestão, serviço social e tecnologias. O conjunto de dados inclui informações conhecidas no momento da matrícula do estudante (trajetória acadêmica, demografia e fatores socioeconômicos) e o desempenho acadêmico dos alunos ao final do primeiro e segundo semestres. Os dados são usados para construir modelos de classificação para prever a evasão e o sucesso acadêmico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BadL4Jqg3zTB",
   "metadata": {
    "id": "BadL4Jqg3zTB"
   },
   "source": [
    "---\n",
    "## O Problema\n",
    "\n",
    "O problema é formulado como uma tarefa de classificação binária indicando a conclusão ou desistência do curso, na qual existe um forte desequilíbrio em favor de uma das classes originais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada3d92-23bf-42bd-a994-6d1143a96b3a",
   "metadata": {
    "id": "eada3d92-23bf-42bd-a994-6d1143a96b3a"
   },
   "source": [
    "---\n",
    "## Explorando os Dados\n",
    "\n",
    "Inicialmente, começamos explorando os dados ao importar as bibliotecas `numpy` e `pandas`. Utilizamos o `pandas` para ler o arquivo 'data.csv', especificando o ponto e vírgula como delimitador.\n",
    "\n",
    "Após a leitura do arquivo, exibimos as primeiras cinco linhas do DataFrame `df` com a função `head()`. Esta visualização inicial nos fornece uma visão rápida de como os dados estão estruturados, incluindo nomes de colunas e tipos de dados, o que é crucial para o planejamento das etapas seguintes de análise.\n",
    "\n",
    "Em seguida, imprimimos a dimensão do DataFrame com `df.shape`, revelando o número total de linhas e colunas. Esta informação é fundamental para entender o volume e a complexidade dos dados com os quais estamos trabalhando, orientando as decisões sobre o processamento e a análise subsequente.\n",
    "\n",
    "Por vim, verificamos a presença de nulos ou valores ausentes, o que não é o caso deste nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3740d-1a65-4b0b-ac17-e3cabf068431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "79e3740d-1a65-4b0b-ac17-e3cabf068431",
    "is_executing": true,
    "outputId": "0284b88e-36ec-452f-8ad0-3dc5942b94fb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "!wget -O data.csv 'https://drive.google.com/uc?export=download&id=1hnHg7IN3qTPnIui2XrkT5hUd9XFH8Ecn'\n",
    "\n",
    "df = pd.read_csv('data.csv', delimiter=';')\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HfjG__rJ3zTC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfjG__rJ3zTC",
    "outputId": "0d129b6d-7d1f-49d2-aeee-eec283f03cf3"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680aUQvI3zTC",
   "metadata": {
    "id": "680aUQvI3zTC"
   },
   "source": [
    "#### Avaliando a Distribuição da Coluna Alvo\n",
    "\n",
    "Prosseguindo com a exploração dos dados, focamos na coluna 'Target', que desempenha um papel crucial na nossa análise. Para entender melhor a distribuição dos valores nesta coluna, utilizamos o método `value_counts()` do Pandas. Este método nos retorna rapidamente um panorama da frequência de cada valor único na coluna 'Target'.\n",
    "\n",
    "Ao realizar esta operação, estamos buscando informações sobre a distribuição das classes ou categorias representadas na coluna 'Target'. Esta informação é vital, pois uma distribuição desigual das classes pode influenciar significativamente o desempenho do modelo.\n",
    "\n",
    "Assim, ao imprimir o resultado de `value_counts()`, estabelecemos uma base para compreender como os dados estão estruturados em relação à variável que pretendemos prever.\n",
    "\n",
    "Como esperado, há um forte desbalanceamento entre os valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58777ce-f459-430c-b656-4e2ac0d9d030",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c58777ce-f459-430c-b656-4e2ac0d9d030",
    "outputId": "1509ee00-1aaf-4e69-c2ca-b9c95bb155f8"
   },
   "outputs": [],
   "source": [
    "print(df['Target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1lcSdIYa3zTC",
   "metadata": {
    "id": "1lcSdIYa3zTC"
   },
   "source": [
    "---\n",
    "## Preparação dos Dados para Modelagem\n",
    "\n",
    "Com o objetivo de adaptar nosso conjunto de dados para um problema de classificação binária, fizemos ajustes focando nas categorias 'Graduate' e 'Dropout'. Criamos a nova coluna 'Dropout' no DataFrame, codificando 'Graduate' como 0 e 'Dropout' como 1, que será nossa variável dependente. Eliminamos a categoria 'Enrolled', o que também contribui para reduzir o desbalanceamento inicial das classes.\n",
    "\n",
    "Com a nova organização dos dados, removemos a coluna 'Target', pois ela já foi codificada em 'Dropout'. Em seguida, separamos o DataFrame em variáveis independentes `X` e a variável dependente `y`, que agora reflete com precisão o nosso problema binário de prever se um aluno irá se formar ou desistir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb3f01-3f5b-4991-8ec8-9c67ebefb9fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05fb3f01-3f5b-4991-8ec8-9c67ebefb9fd",
    "outputId": "680e780b-7577-47e6-96c0-d32552f3d3ea"
   },
   "outputs": [],
   "source": [
    "df = df[df['Target'].isin(['Graduate', 'Dropout'])]\n",
    "\n",
    "df['Dropout'] = [0 if typ == 'Graduate' else 1 for typ in df['Target']]\n",
    "\n",
    "df.drop('Target', axis=1, inplace=True)\n",
    "\n",
    "X = df.drop('Dropout', axis=1)\n",
    "\n",
    "y = df['Dropout']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d3309-0cae-4836-82f4-b606bdfa3af2",
   "metadata": {
    "id": "e75d3309-0cae-4836-82f4-b606bdfa3af2"
   },
   "source": [
    "---\n",
    "## Separando os Dados em Treinamento e Teste\n",
    "\n",
    "Agora avançamos para  a divisão do conjunto de dados em partes para treinamento e teste. Ao definirmos o parâmetro `test_size` como 0.3, estamos especificando que 30% do conjunto de dados será reservado para teste e 70% para treinar o modelo, conforme solicitado.\n",
    "\n",
    "Após a aplicação da `train_test_split`, obtemos quatro conjuntos de dados: `X_train` e `y_train`, utilizados para treinamento, e `X_test` e `y_test`, que servirão para testar o modelo após o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e6f17-20fc-4cb5-abb7-d79e93980a9e",
   "metadata": {
    "id": "d22e6f17-20fc-4cb5-abb7-d79e93980a9e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d610e4-df4e-4b4c-902b-528582b2bb7a",
   "metadata": {
    "id": "62d610e4-df4e-4b4c-902b-528582b2bb7a"
   },
   "source": [
    "---\n",
    "## Normalizando os Dados\n",
    "\n",
    "Iniciamos este processo utilizando o método `describe()` do DataFrame, que fornece um resumo estatístico, como média, desvio padrão, valores mínimos e máximos. Esta visão permite identificar a necessidade de normalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4e052-6da0-447a-b73e-4f52aa233078",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "aea4e052-6da0-447a-b73e-4f52aa233078",
    "outputId": "34eebf41-d110-49b0-8fcf-4e575907baf9"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ce432-440b-43a4-ad61-709c7b9738aa",
   "metadata": {
    "id": "808ce432-440b-43a4-ad61-709c7b9738aa"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be7e39-b1f8-4c01-8261-16708722f02e",
   "metadata": {
    "id": "59be7e39-b1f8-4c01-8261-16708722f02e"
   },
   "source": [
    "---\n",
    "## Definindo o Modelo de Rede Neural\n",
    "\n",
    "Determinamos o número de características de entrada (`shape`) com base na forma do conjunto de dados de teste (`X_test`). Esse número guia a configuração da primeira camada da rede.\n",
    "\n",
    "O modelo é construído como uma sequência de camadas, cada uma com a função de ativação `relu`, exceto a última camada que utiliza `sigmoid`. A primeira camada recebe `shape` neurônios, correspondendo ao número de características de entrada. A segunda camada tem metade do número de neurônios da primeira, seguindo uma estrutura que gradualmente condensa a informação. A última camada, com um único neurônio e ativação `sigmoid`, é adequada para uma tarefa de classificação binária, produzindo uma saída entre 0 e 1.\n",
    "\n",
    "Após a definição do modelo, invocamos `model.summary()` para exibir um resumo da arquitetura da rede. Observamos que o modelo consiste em três camadas, com um total de 417 parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367069e9-1dfe-429e-862a-4992107d9d53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "367069e9-1dfe-429e-862a-4992107d9d53",
    "outputId": "06e1126e-afb4-4c30-f290-5c1263639a9e"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "shape = X_test.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(shape, activation='relu', input_shape=[shape]),\n",
    "    layers.Dense(shape / 2, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e95c9c-8aa4-432d-ad5f-4ee853d3e07b",
   "metadata": {
    "id": "71e95c9c-8aa4-432d-ad5f-4ee853d3e07b"
   },
   "source": [
    "---\n",
    "## Compilando o Modelo de Rede Neural\n",
    "\n",
    "Escolhemos 'binary_crossentropy' como a função de perda e definimos 'binary_accuracy' como a métrica para avaliar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2ac34-9030-4aa2-8e75-21d36262dd02",
   "metadata": {
    "id": "bec2ac34-9030-4aa2-8e75-21d36262dd02"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d03a1e-ce56-4ce2-83b4-8c26d5a5ff49",
   "metadata": {
    "id": "56d03a1e-ce56-4ce2-83b4-8c26d5a5ff49"
   },
   "source": [
    "---\n",
    "## Treinamento do Modelo com Early Stopping\n",
    "\n",
    "Utilizamos a técnica de early stopping para melhorar a eficiência e prevenir o overfitting.\n",
    "\n",
    "Configuramos este callback para iniciar a avaliação da necessidade de parada após 10 épocas (`start_from_epoch=10`), com uma paciência de 10 épocas adicionais (`patience=10`). O parâmetro `restore_best_weights=True` garante que o modelo retorne aos pesos da época em que teve o melhor desempenho após a parada do treinamento.\n",
    "\n",
    "Passamos `X_train` e `y_train` como os dados de treinamento, com um `batch_size` de 32. Utilizamos uma divisão de validação de 30% (`validation_split=0.3`) para avaliar o desempenho do modelo. O modelo é treinado para um máximo de 100 épocas (`epochs=100`), mas com a parada antecipada, podemos observar que o treinamento terminou antes deste limite.\n",
    "\n",
    "Ao final do treinamento, o histórico é armazenado em `history`. Este histórico contém informações valiosas sobre a evolução da função de perda e das métricas de avaliação ao longo das épocas, permitindo a análise posterior do desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21d31d-6464-469d-ac40-fde9522eed69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc21d31d-6464-469d-ac40-fde9522eed69",
    "outputId": "747eb9cc-853d-4e7b-a48b-97a9eb8302ca"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    start_from_epoch=10,\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    validation_split=0.3,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd9b7cc-4f7d-44f3-80c1-f90b39fada35",
   "metadata": {
    "id": "7bd9b7cc-4f7d-44f3-80c1-f90b39fada35"
   },
   "source": [
    "---\n",
    "## Curva de Aprendizado e Avaliação do Desempenho do Modelo\n",
    "\n",
    "Depois o treinamento, transformamos o histórico m um DataFrame para análise.\n",
    "\n",
    "Os gráficos apresentam a evolução da perda e da acurácia ao longo das épocas. Observamos que a perda no conjunto de validação diminui de forma consistente ao longo do tempo, o que indica que o modelo está aprendendo efetivamente e melhorando a sua capacidade de generalização. Além disso, a acurácia binária no conjunto de validação aumenta e parece estabilizar, sugerindo que o modelo não está apenas memorizando os dados de treinamento, mas também se tornando eficaz em prever resultados em dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9528848-2aae-46cd-be41-10f320a1d7c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c9528848-2aae-46cd-be41-10f320a1d7c4",
    "outputId": "c204f241-50db-457b-c695-6652d8498672"
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "display(history_df.head())\n",
    "# Start the plot at epoch 0\n",
    "history_df.loc[0:, ['loss', 'val_loss']].plot()\n",
    "history_df.loc[0:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "\n",
    "print((\"Best Validation Loss: {:0.4f}\" +\\\n",
    "  \"\\nBest Validation Accuracy: {:0.4f}\")\\\n",
    "  .format(history_df['val_loss'].min(),\n",
    "          history_df['val_binary_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af5783-ee8b-4e5a-af3a-eafbc5f6a3e8",
   "metadata": {
    "id": "d5af5783-ee8b-4e5a-af3a-eafbc5f6a3e8"
   },
   "source": [
    "---\n",
    "## Avaliação Final do Modelo\n",
    "\n",
    "Concluído o treinamento do modelo de rede neural, procedemos à sua avaliação usando o conjunto de teste (`X_test`). A predição do modelo é feita através do método `predict`, e um threshold de 0.5 é aplicado para determinar a classificação binária: valores iguais ou acima de 0.5 são considerados classe 1 (Dropout) e abaixo são classe 0 (Graduate).\n",
    "\n",
    "A matriz de confusão revelada indica que o modelo teve um desempenho razoavelmente bom ao identificar as duas classes, com um número maior de verdadeiros positivos e verdadeiros negativos do que de falsos positivos e falsos negativos.\n",
    "\n",
    "Em seguida, apresentamos o relatório de classificação, que oferece uma visão detalhada do desempenho do modelo, incluindo métricas como precisão, recall e pontuação f1 para cada classe. O relatório mostra que o modelo tem uma precisão e um recall balanceados para ambas as classes, resultando em uma boa pontuação f1.\n",
    "\n",
    "Por último, calculamos a acurácia geral do modelo, que nos informa a proporção de previsões corretas sobre o total de previsões. Com uma acurácia de aproximadamente 88%, podemos concluir que o modelo é bastante eficaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fe76f-07bd-42cd-ab9c-21498da2e2e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e83fe76f-07bd-42cd-ab9c-21498da2e2e0",
    "outputId": "af2d956c-2140-4f82-a8a3-507ca42a594f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test) >= 0.5\n",
    "\n",
    "print('Matriz de Confusão: \\n' , confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('Acuracidade: ' , accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hZACoXstFIL7",
   "metadata": {
    "id": "hZACoXstFIL7"
   },
   "source": [
    "---\n",
    "## Conclusões\n",
    "\n",
    "Ao finalizar a análise e modelagem do conjunto de dados, concluímos que as redes neurais, com o uso do TensorFlow e Keras, demonstraram ser ferramentas eficazes para prever a evasão e o sucesso acadêmico de estudantes.\n",
    "\n",
    "A aplicação de técnicas como normalização e early stopping contribuíram significativamente para a eficácia do modelo.\n",
    "\n",
    "A precisão alcançada, em torno de 87%, sugere que o modelo pode ser uma ferramenta valiosa para identificar estudantes em risco, permitindo intervenções proativas para melhorar a retenção e o sucesso acadêmico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd873874-7983-4635-a0d5-aa1cb037bfdf",
   "metadata": {
    "id": "fd873874-7983-4635-a0d5-aa1cb037bfdf"
   },
   "source": [
    "---\n",
    "## Referências\n",
    "\n",
    "1. University of California, Irvine. Predict Student's Dropout and Academic Success. UCI Machine Learning Repository. Disponível em: https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success. Acesso em: 23 nov.2023.\n",
    "\n",
    "2. BETTER-DATA-SCIENCE. TensorFlow Classification. 2023. Software. Disponível em: https://github.com/better-data-science/TensorFlow/blob/main/003_TensorFlow_Classification.ipynb. Acesso em: 22 nov.2023."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
